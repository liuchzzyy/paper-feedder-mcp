# paper-feed 框架指南

> 本文档为 AI agent 及人类开发者提供 paper-feed 代码库的全面说明：架构、规范、数据流与约束。

---

## 1. 项目概述

**paper-feed** 是一个模块化 Python 框架，用于从 RSS 订阅源和 Gmail 邮件提醒中收集、过滤和导出学术论文。

- **语言**: Python 3.10+
- **异步优先**: 所有 I/O 操作使用 `async/await`
- **包管理器**: `uv`（锁文件: `uv.lock`），构建后端: `hatchling`
- **代码检查/格式化**: `ruff`（行宽 88，目标 py310）
- **类型检查**: `ty`（Red Knot）
- **测试**: `pytest` + `pytest-asyncio`（模式: `auto`）
- **数据模型**: `pydantic` v2（`BaseModel`）

---

## 2. 目录结构

```
paper-feed/
├── pyproject.toml             # 项目配置、依赖、工具设置
├── README.md                  # 面向用户的文档（英文）
├── 中文指南.md                # ← 本文件（框架指南）
├── .env.example               # 环境变量模板
├── .gitignore                 # Git 忽略文件
│
├── src/paper_feed/            # 主包
│   ├── __init__.py            # 公共 API 导出，可选依赖守卫
│   │
│   ├── core/                  # 核心模型与抽象基类
│   │   ├── __init__.py        # 导出: PaperItem, FilterCriteria, FilterResult, PaperSource, ExportAdapter
│   │   ├── base.py            # ABC: PaperSource, ExportAdapter
│   │   ├── models.py          # Pydantic: PaperItem, FilterCriteria, FilterResult
│   │   ├── cli.py             # CLI 命令行接口（argparse）
│   │   └── config.py          # 环境配置管理（python-dotenv）
│   │
│   ├── sources/               # 数据源实现
│   │   ├── __init__.py        # 导出: RSSSource, GmailSource, CrossrefClient, OpenAlexClient
│   │   ├── rss.py             # RSSSource(PaperSource) — 基于 OPML 的并发 RSS 抓取
│   │   ├── rss_parser.py      # RSSParser — feedparser entry → PaperItem 转换
│   │   ├── gmail.py           # GmailSource(PaperSource) — 基于 ezgmail 的邮件抓取
│   │   ├── gmail_parser.py    # GmailParser — HTML 邮件 → PaperItem 提取（3 策略）
│   │   ├── opml.py            # OPMLParser — OPML XML → 订阅源 URL 列表
│   │   ├── crossref.py        # CrossrefClient — CrossRef API 元数据补充
│   │   └── openalex.py        # OpenAlexClient — OpenAlex API 元数据补充
│   │
│   ├── ai/                    # AI 模块
│   │   ├── __init__.py        # 导出: KeywordGenerator, AIFilterStage
│   │   ├── keyword_generator.py # OpenAI 驱动的关键词生成
│   │   └── ai_filter.py       # LLM 语义论文过滤
│   │
│   ├── filters/               # 过滤管道
│   │   ├── __init__.py        # 导出: FilterPipeline, KeywordFilterStage
│   │   ├── pipeline.py        # FilterPipeline — 顺序阶段编排器
│   │   └── keyword.py         # KeywordFilterStage — OR/NOT 关键词逻辑
│   │
│   ├── adapters/              # 导出适配器
│   │   ├── __init__.py        # 导出: JSONAdapter, ZoteroAdapter（可选）
│   │   ├── json.py            # JSONAdapter(ExportAdapter) — JSON 文件导出
│   │   └── zotero.py          # ZoteroAdapter(ExportAdapter) — Zotero API 导出（需要 zotero-core）
│   │
│   └── utils/                 # 共享工具
│       ├── __init__.py        # 导出: clean_title, clean_html, clean_abstract, DOI_PATTERN
│       └── text.py            # 文本清理函数和 DOI 正则表达式
│
├── tests/
│   ├── __init__.py
│   └── unit/
│       ├── __init__.py
│       ├── test_rss_source.py     # RSSSource + OPMLParser 测试
│       ├── test_gmail_source.py   # GmailSource 测试
│       ├── test_gmail_parser.py   # GmailParser HTML 解析测试
│       ├── test_adapters.py       # JSONAdapter + ZoteroAdapter 测试
│       ├── test_filters.py        # FilterPipeline + KeywordFilterStage 测试
│       ├── test_config.py         # 配置管理测试
│       ├── test_cli.py            # CLI 接口测试
│       ├── test_ai.py             # AI 模块测试（KeywordGenerator + AIFilterStage）
│       ├── test_crossref.py       # CrossrefClient 测试
│       ├── test_openalex.py       # OpenAlexClient 测试
│       └── test_pipeline_ai.py    # 管道与 AI 阶段集成测试
│
└── feeds/
    └── RSS_official.opml      # 默认 OPML 文件（学术 RSS 订阅源）
```

---

## 3. 架构与数据流

### 分层架构

```
用户代码 / CLI (cli.py)
        │
        ▼
┌─────────────────────────────────────────────────┐
│           公共 API  (__init__.py)                │
│  RSSSource, GmailSource, FilterPipeline,        │
│  JSONAdapter, ZoteroAdapter, PaperItem, etc.     │
└─────────────────────────────────────────────────┘
        │
   ┌────┼────────────┬────────────┐
   ▼    ▼            ▼            ▼
Sources  Filters      AI        Adapters
   │       │          │           │
   └───────┼──────────┴───────────┘
           ▼
     核心模型
  (PaperItem, FilterCriteria, FilterResult)
```

### 数据流（主管道）

```
Source.fetch_papers()  →  List[PaperItem]
        │
        ▼
FilterPipeline.filter(papers, criteria)  →  FilterResult
        │
        ▼
Enrichment (CrossrefClient / OpenAlexClient)  →  List[PaperItem]（补充后）
        │
        ▼
Adapter.export(filtered_papers)  →  输出文件 / API
```

### 详细流程

```
CLI (fetch) → RSSSource / GmailSource
    │
    ├─ [RSSSource] HTTP GET (httpx async) → feedparser.parse()（线程化）→ RSSParser.parse(entry) → PaperItem
    │
    ├─ [GmailSource] ezgmail.search() → _extract_html_body() → GmailParser.parse(html) → PaperItem
    │
    ▼
List[PaperItem]（已去重）
    │
    ▼
CLI (filter) → FilterPipeline
    ├─ KeywordFilterStage（keywords OR 一级宽筛选, exclude NOT, authors OR, min_date, has_pdf）
    ├─ AIFilterStage（LLM 语义相关性二级精选）
    ▼
FilterResult { papers, total_count, passed_count, rejected_count, filter_stats }
    │
    ▼
CLI (enrich) → CrossrefClient / OpenAlexClient
    ├─ DOI 查找 / 标题搜索 → 元数据提取 → PaperItem 补充
    ▼
List[PaperItem]（已补充）
    │
    ▼
CLI (export) → JSONAdapter / ZoteroAdapter
    ├─ JSONAdapter.export() → JSON 文件
    └─ ZoteroAdapter.export() → Zotero API
```

---

## 4. 核心组件参考

### 4.1 PaperItem（Pydantic BaseModel）

通用论文表示。所有数据源产出此对象；所有适配器消费此对象。

```python
class PaperItem(BaseModel):
    title: str                              # 必填 — 论文标题
    authors: List[str] = []                 # 作者姓名列表
    abstract: str = ""                      # 摘要/概要
    published_date: Optional[date] = None   # 发表日期
    doi: str = ""                           # DOI 字符串（无前缀，默认空）
    url: Optional[str] = None               # 论文 URL
    pdf_url: Optional[str] = None           # PDF 直链
    source: str                             # 必填 — 来源名称（"arXiv", "Nature", "Google Scholar"）
    source_id: Optional[str] = None         # 来源特定 ID
    source_type: str                        # 必填 — "rss" 或 "email"
    metadata: Dict[str, Any] = {}           # 可扩展的来源特定数据
```

**约束：**
- `title`、`source` 和 `source_type` 始终必填；`doi` 默认为空字符串
- `metadata` 是来源特定数据的扩展字段 — 应优先使用它而非修改模型 schema
- 所有可变类型的默认值使用 `Field(default_factory=...)`

### 4.2 PaperSource（ABC）

```python
class PaperSource(ABC):
    source_name: str = "base"
    source_type: str = "base"

    @abstractmethod
    async def fetch_papers(
        self, limit: Optional[int] = None, since: Optional[date] = None
    ) -> List[PaperItem]: ...
```

**实现类：** `RSSSource`, `GmailSource`

### 4.3 ExportAdapter（ABC）

```python
class ExportAdapter(ABC):
    @abstractmethod
    async def export(self, papers: List[PaperItem], **kwargs: Any) -> Any: ...
```

**实现类：** `JSONAdapter`, `ZoteroAdapter`

### 4.4 FilterCriteria 与 FilterResult

```python
class FilterCriteria(BaseModel):
    keywords: List[str] = []           # OR 逻辑 — 任一匹配即通过（一级宽筛选）
    exclude_keywords: List[str] = []   # NOT 逻辑 — 任一匹配则排除
    min_date: Optional[date] = None
    authors: List[str] = []            # OR 逻辑
    has_pdf: bool = False

class FilterResult(BaseModel):
    papers: List[PaperItem]
    total_count: int
    passed_count: int
    rejected_count: int
    filter_stats: Dict[str, Any] = {}
```

---

## 5. 数据源实现

### 5.1 RSSSource (`sources/rss.py`)

- **输入**: OPML 文件路径（构造函数）— 解析顺序: 显式参数 → `PAPER_FEED_OPML` 环境变量 → `feeds/RSS_official.opml`
- **依赖**: `feedparser`, `httpx`, `OPMLParser`, `RSSParser`
- **并发控制**: `asyncio.Semaphore(max_concurrent)` 控制并行抓取
- **去重**: 按 URL 跨所有订阅源去重
- **错误处理**: 失败的订阅源记录日志并跳过；处理继续
- **来源名称检测**: URL 模式匹配已知出版商（arXiv, Nature 等）

### 5.2 RSSParser (`sources/rss_parser.py`)

将单个 feedparser entry 字典转换为 `PaperItem`。提取内容：
- **标题**: `entry.title`（必填）
- **作者**: `entry.authors`（字典/对象列表，含 `.name`）→ 回退 `entry.author`（字符串，按 `,` / `;` / ` and ` 分割）
- **摘要**: `entry.summary` → 回退 `entry.description`
- **日期**: `entry.published_parsed` → 回退 `entry.updated_parsed`（均为 `time.struct_time`）
- **DOI**: `entry.dc_identifier` / `entry.prism_doi` → 回退在 `entry.link` / `entry.id` 中用 DOI 正则匹配
- **PDF URL**: `entry.links` 中 `type="application/pdf"` → `entry.pdf_url` → arXiv `/abs/` → `/pdf/` 转换

### 5.3 GmailSource (`sources/gmail.py`)

- **输入**: Gmail 搜索查询字符串（与 Gmail 搜索框语法相同）
- **依赖**: `ezgmail`（可选），`GmailParser`
- **延迟初始化**: `_ensure_init()` 在首次使用时调用 `_write_json_configs()`（将内联 JSON 写入文件）再调用 `ezgmail.init()`
- **HTML 提取**: 自定义 `_extract_html_body()` / `_find_html_in_payload()` — 递归遍历 `message.messageObj` payload 查找 `TEXT/HTML` 部分并进行 base64 解码。**这是必要的，因为 ezgmail 只提取纯文本。**
- **去重**: 按标题（不区分大小写）跨所有邮件去重
- **功能**: 日期过滤、标记已读、限制数量

### 5.4 GmailParser (`sources/gmail_parser.py`)

使用三种策略解析 HTML 邮件内容（按顺序尝试）：
1. **表格行**: 扫描 `<table>` → `<tr>` 行中的文章链接（常见于期刊目录邮件）
2. **Div/article/section**: 扫描 `<div>`, `<article>`, `<section>` 容器中的链接 + 标题
3. **独立链接**: 扫描所有 `<a>` 标签，按已知出版商域名过滤

每种策略提取: 标题、URL、DOI（正则）、作者（启发式）、期刊/类别。
结果按标题（不区分大小写）去重。

### 5.5 OPMLParser (`sources/opml.py`)

解析 OPML XML 文件以提取 RSS 订阅源 URL。处理：
- 嵌套类别（递归 outline 遍历）
- `type="rss"` 过滤
- 类别保留
- 环境变量和默认路径解析

### 5.6 CrossrefClient (`sources/crossref.py`)

- **用途**: CrossRef API 客户端，用于 DOI 查找和论文元数据补充。
- **核心类**: `CrossrefWork`（dataclass）— 表示 CrossRef 中的一个作品。
- **方法**:
  - `search_by_title(title, rows)`: 按标题搜索作品。
  - `get_by_doi(doi)`: 按 DOI 获取作品元数据。
  - `find_best_match(title, threshold)`: 使用 Jaccard 相似度查找最佳匹配。
  - `enrich_paper(paper)`: 补充 `PaperItem` 的缺失元数据。
  - `_clean_doi(doi)`: 去除常见 DOI URL 前缀。

### 5.7 OpenAlexClient (`sources/openalex.py`)

- **用途**: OpenAlex API 客户端，用于开放元数据补充。
- **核心类**: `OpenAlexWork`（dataclass）— 表示 OpenAlex 中的一个作品。
- **方法**:
  - `search_by_title(title, per_page)`: 按标题搜索作品。
  - `get_by_doi(doi)`: 按 DOI 获取作品元数据。
  - `find_best_match(title, threshold)`: 使用 Jaccard 相似度查找最佳匹配。
  - `enrich_paper(paper)`: 补充 `PaperItem` 的缺失元数据。
  - `_reconstruct_abstract(inverted_index)`: 从 OpenAlex 倒排索引重建摘要。

---

## 6. 过滤系统

### 两级筛选设计

```
200 papers (RSS 原始抓取)
    │
    ▼  Stage 1: KeywordFilterStage (OR 逻辑, 宽进)
   12 papers
    │
    ▼  Stage 2: AIFilterStage (LLM 语义精选, 严出)
    1 paper
```

- **一级（关键词 OR）**: 快速、低成本的宽筛选。标题或摘要中包含任意一个关键词即通过。
- **二级（AI 精选）**: 使用 LLM 根据研究兴趣 prompt 判断语义相关性，精确过滤。

这种设计确保：关键词阶段不会误杀相关论文（宽进），AI 阶段负责精确判断（严出）。

### FilterPipeline (`filters/pipeline.py`)

顺序阶段编排器。目前有两个阶段：
- `KeywordFilterStage` — 当任何条件字段非默认值时运行（OR 逻辑一级宽筛选）
- `AIFilterStage` — LLM 驱动的语义过滤（可选，需要 `llm_client`，二级精选）

### KeywordFilterStage (`filters/keyword.py`)

按顺序应用过滤器（首次失败即提前退出）：
1. **排除关键词**（OR — 任一匹配则排除）在标题+摘要中
2. **关键词**（OR — 任一匹配即通过）在标题+摘要中，作为一级宽筛选
3. **作者**（OR — 任一匹配）对照 `paper.authors`
4. **PDF 可用性** — 要求 `pdf_url is not None`
5. **最早日期** — 要求 `published_date >= min_date`（无日期的论文通过）

所有字符串匹配不区分大小写，基于子字符串。

---

## 7. AI 模块 (`ai/`)

AI 模块使用 OpenAI 兼容 API 提供高级过滤和关键词生成能力。

### 7.1 KeywordGenerator (`ai/keyword_generator.py`)

从自然语言提示中提取研究关键词并与论文匹配。
- **提取**: 两阶段管道（生成候选词 → 选择最佳 10 个）。
- **匹配**: 5 策略灵活匹配：
  1. 精确子字符串（标准化）
  2. 全词匹配（关键词的所有单词都出现在文本中）
  3. 词干匹配（简单后缀去除）
  4. 化学同义词匹配（如 "Zinc" <-> "Zn"）
  5. 核心术语匹配（如 "operando", "in-situ"）
- **缓存**: 结果基于提示哈希缓存在 `cache/keywords_cache.json` 中。

### 7.2 AIFilterStage (`ai/ai_filter.py`)

LLM 驱动的语义相关性判断。
- **批处理**: 按批次处理论文（默认: 50 篇）以优化 API 使用。
- **提示**: 使用自然语言研究兴趣来判断相关性。
- **解析**: 使用 3 种策略从 LLM 响应中提取 JSON 的鲁棒解析。
- **失败开放**: 如果 API 调用或解析失败，返回所有论文，确保不因技术错误丢失论文。

---

## 8. 配置系统 (`core/config.py`)

使用 `python-dotenv` 的集中式配置管理。

- **Dotenv 集成**: 通过 `_ensure_dotenv()` 从项目根目录或 CWD 延迟加载 `.env` 文件。使用 `override=True` 确保 `.env` 值优先于系统环境变量。
 - **类型化访问器**:
   - `get_openai_config()`: API 密钥、模型、基础 URL。
   - `get_gmail_config()`: Token JSON / 凭证 JSON（内联，必填）、搜索查询、发件人过滤。
   - `get_zotero_config()`: 库 ID、API 密钥、类型。
   - `get_rss_config()`: OPML 路径、User-Agent、超时、最大并发。
   - `get_crossref_config()` / `get_openalex_config()`: 通过 `_get_shared_api_defaults()` 共享 `POLITE_POOL_EMAIL`、`API_TIMEOUT`、`API_USER_AGENT`，支持每服务覆盖。
   - `get_research_prompt()`: 自然语言研究兴趣（从环境变量或文件获取）。
   - `get_ai_filter_config()`: AI 批次大小、最大 token。
   - `get_keyword_generator_config()`: 关键词生成/选择最大 token。

### Gmail OAuth2 配置

只支持内联 JSON 方式：
- `GMAIL_TOKEN_JSON`: OAuth2 token JSON 字符串（必填）
- `GMAIL_CREDENTIALS_JSON`: OAuth2 credentials JSON 字符串（必填）

JSON 值在启动时自动写入固定文件路径（token.json / credentials.json）以兼容 EZGmail。

### 共享 API 配置

CrossRef 和 OpenAlex 共享以下默认值，避免重复配置：
- `POLITE_POOL_EMAIL` → 共享邮箱
- `API_TIMEOUT` → 共享超时
- `API_USER_AGENT` → 共享 User-Agent

每个服务可通过 `CROSSREF_*` / `OPENALEX_*` 前缀的环境变量覆盖共享值。

---

## 9. 命令行接口 (`core/cli.py`)

`paper-feed` CLI 为所有框架操作提供统一接口。

### 子命令

- **`fetch`**: 从数据源收集论文。
  - `--source`: `rss`（默认）或 `gmail`。
  - `--opml`: OPML 文件路径（用于 RSS）。
  - `--query`: Gmail 搜索查询。
  - `--limit` / `--since`: 抓取约束。
- **`filter`**: 应用过滤管道。
  - `--input` / `--output`: JSON 文件路径。
  - `--keywords`: 关键词过滤（OR 逻辑，一级宽筛选）。
  - `--authors` / `--exclude`: 作者/排除关键词过滤。
  - `--min-date` / `--has-pdf`: 元数据过滤。
  - `--ai`: 启用 LLM 语义过滤。
- **`enrich`**: 通过外部 API 进行元数据补充。
  - `--source`: `crossref`、`openalex` 或 `all`（默认）。
  - `--concurrency`: 最大并行 API 请求数（默认: 5）。
- **`export`**: 导出论文到目标格式。
  - `--format`: `json`（默认）或 `zotero`。
  - `--include-metadata`: 包含来源特定元数据。

---

## 10. 适配器系统

### JSONAdapter (`adapters/json.py`)

- 将 `List[PaperItem]` 导出为 JSON 文件
- 将 `date` 对象转换为 ISO 格式字符串
- 可选 `include_metadata` 标志
- 自动创建父目录
- UTF-8 编码，美化输出（indent=2）

### ZoteroAdapter (`adapters/zotero.py`)

- 通过 `zotero-core`（可选依赖）导出到 Zotero 库
- 将 PaperItem 转换为 Zotero `journalArticle` 格式
- 批处理，每项错误单独处理

---

## 11. 工具函数 (`utils/text.py`)

- `clean_title(title)` — 去除 `[DOI]`、`[PDF]` 等前缀
- `clean_html(raw_html)` — 去除 HTML 标签
- `clean_abstract(abstract)` — 完整摘要清理: HTML 实体、XML/JATS 标签、嵌入的 DOI/URL、空白标准化
- `DOI_PATTERN` — 编译的正则表达式: `r"10\.\d{4,9}/[-._;()/:A-Z0-9]+"` （不区分大小写）

---

## 12. 依赖

### 必选依赖
| 包 | 用途 |
|---|------|
| `feedparser>=6.0.0` | RSS/Atom 订阅源解析 |
| `pydantic>=2.0.0` | 带验证的数据模型 |
| `httpx>=0.25.0` | 异步 HTTP 客户端 |
| `python-dateutil>=2.8.0` | 日期解析 |
| `beautifulsoup4>=4.12.0` | HTML 解析（Gmail 邮件） |
| `ezgmail>=0.1.0` | Gmail API 访问 |
| `openai>=1.0.0` | AI 驱动的过滤与关键词生成 |
| `python-dotenv>=1.0.0` | 环境变量管理 |

### 可选依赖
| 包 | Extra | 用途 |
|---|-------|------|
| `zotero-core` | `[zotero]` | Zotero API 导出 |

### 开发依赖
| 包 | 用途 |
|---|------|
| `pytest>=7.0.0` | 测试 |
| `pytest-asyncio>=0.21.0` | 异步测试支持 |
| `ruff>=0.1.0` | 代码检查 + 格式化 |
| `ty` | 类型检查（Red Knot） |

---

## 13. 设计模式

| 模式 | 位置 | 用途 |
|------|------|------|
| **抽象工厂** | `PaperSource`, `ExportAdapter` | 通过统一接口实现可互换的数据源/适配器 |
| **管道** | `FilterPipeline` | 顺序阶段处理 |
| **策略** | Adapters | 运行时选择导出策略 |
| **可选依赖** | `__init__.py`, `adapters/__init__.py`, `sources/__init__.py` | 通过 `try/except ImportError` 优雅导入 |
| **关注点分离** | 模块结构 | 数据源抓取、过滤器过滤、适配器导出 |
| **异步优先** | 所有公共 API | 通过 `async/await` 实现非阻塞 I/O |
| **配置** | `core/config.py` | 基于 dotenv 的集中配置 |
| **元数据补充** | `sources/crossref.py`, `sources/openalex.py` | 过滤后通过外部 API 补充元数据 |
| **失败开放** | `ai/ai_filter.py` | AI 过滤出错时返回所有论文 |

---

## 14. 编码规范

### 风格
- **行宽**: 88 字符（ruff）
- **目标 Python**: 3.10+
- **导入顺序**: 标准库 → 第三方 → 本地（空行分隔）
- **文档字符串**: Google 风格，包含 Args/Returns/Raises 段落
- **类型注解**: 所有地方。使用 `Optional[T]` 而非 `T | None`（3.10 兼容）
- **日志**: 每个模块使用 `logging.getLogger(__name__)`

### 代码模式
- **异步包装**: 对阻塞调用使用 `asyncio.to_thread()`（feedparser, ezgmail）
- **错误处理**: 记录日志 + 跳过无效项；不因单个坏条目崩溃管道
- **去重**: 始终对结果去重（RSS 按 URL，Gmail 按标题）
- **字段访问**: 使用 `_get_field(entry, key, default)` 模式安全访问字典/对象
- **可选依赖**: 在 `try/except ImportError` 块中导入；设置模块级标志

### 应避免的反模式
- **不要使用** `as any`、`@ts-ignore` 等价物 — 不要抑制类型错误
- **不要更改 PaperItem schema** 除非绝对必要 — 使用 `metadata` 字典替代
- **不要破坏 ABC 接口** — `PaperSource.fetch_papers()` 和 `ExportAdapter.export()` 签名是契约
- **不要为可选功能添加必选依赖** — 在 `pyproject.toml` 中使用 optional extras

---

## 15. 测试规范

- **框架**: `pytest` + `pytest-asyncio`（模式: `auto` — 无需 `@pytest.mark.asyncio` 装饰器）
- **Mock**: `unittest.mock` — `MagicMock`, `AsyncMock`, `patch`
- **外部依赖**: 始终 mock HTTP 调用和 ezgmail；单元测试中绝不访问真实 API
- **集成测试**: 网络调用的集成测试在离线时跳过（`pytest.skip`）
- **测试结构**: 每个源模块一个测试文件，按功能/策略组织
- **总计：350 通过，2 跳过（Zotero 可选依赖），0 失败**

### 运行测试
```bash
# 所有测试
pytest

# 详细输出
pytest -v

# 指定文件
pytest tests/unit/test_rss_source.py -v
```

---

## 16. 不可违反的约束

1. **保留框架逻辑**: 分层架构（core → sources/filters/adapters）不可更改。
2. **保留 ABC 接口**: `PaperSource.fetch_papers()` 和 `ExportAdapter.export()` 签名是契约。
3. **保留 PaperItem schema**: 使用 `metadata` 字典进行来源特定扩展；不要在没有充分理由的情况下添加新的顶层字段。
4. **不破坏现有测试**: 所有 350 个测试必须继续通过。
5. **可选依赖保持可选**: Gmail、LLM、Zotero 功能必须在 `try/except ImportError` 后面工作。
6. **保留 `_extract_html_body` / `_find_html_in_payload`**: ezgmail 缺少 HTML 提取 — 这些是必要的。
7. **异步优先**: 新的 I/O 操作必须是异步的；使用 `asyncio.to_thread()` 包装阻塞调用。
8. **优雅降级**: 不因单个坏条目/邮件/订阅源崩溃管道。
9. **秘密信息放 `.env`**: 绝不在代码中硬编码 API 密钥、Token 或凭证。
10. **AI 过滤失败开放**: AI 过滤出错时必须返回所有论文，防止数据丢失。

---

## 附录 A: 扩展指南

### 添加新的数据源
1. 创建 `sources/new_source.py`，类继承 `PaperSource`
2. 实现 `async def fetch_papers(self, limit, since) -> List[PaperItem]`
3. 在 `sources/__init__.py` 中添加导出（如有可选依赖则使用 `try/except`）
4. 在 `__init__.py` 中添加公共导出
5. 在 `tests/unit/test_new_source.py` 中添加测试

### 添加新的过滤阶段
1. 创建阶段类，包含 `async def filter(papers, criteria) -> Tuple[List[PaperItem], List[str]]`
2. 添加 `is_applicable(criteria) -> bool` 方法
3. 在 `FilterPipeline.__init__` 和 `FilterPipeline.filter()` 中注册

### 添加新的适配器
1. 创建 `adapters/new_adapter.py`，继承 `ExportAdapter`
2. 实现 `async def export(self, papers, **kwargs)`
3. 在 `adapters/__init__.py` 中添加导出
4. 在 `__init__.py` 中添加公共导出
5. 添加测试

---

## 附录 B: 关键外部库用法

### feedparser（RSS 解析）

在 `sources/rss.py` 和 `sources/rss_parser.py` 中使用。

**我们使用的功能：**
- `feedparser.parse(content)` → 解析后的 feed 对象
- `feed.entries` → entry 字典列表
- `entry.title`, `entry.link`, `entry.id`
- `entry.summary` / `entry.description` → 摘要
- `entry.authors`（`{name, email}` 字典列表）/ `entry.author`（字符串）
- `entry.published_parsed` / `entry.updated_parsed` → `time.struct_time`
- `entry.tags` → `{term, scheme, label}` 字典列表
- `entry.links` → 包含 `type`, `href`, `rel` 的链接字典列表
- `entry.dc_identifier`, `entry.prism_doi` → DOI 字段
- `feed.bozo` / `feed.bozo_exception` → 解析错误检测
- `entry.content` — 富内容数组（Atom feeds）
- `entry.enclosures` — 媒体/PDF 附件
- `entry.publisher` / `entry.publisher_detail` — 出版商信息
- `entry.contributors` — 其他贡献者
- `entry.rights` — 版权/许可
- `entry.source` — 聚合 feed 的原始来源
- `*_detail` 字段 — `title_detail`, `summary_detail`，包含类型/语言元数据
- Feed 级别: `feed.title`, `feed.subtitle`, `feed.language`, `feed.version`, `feed.encoding`

**可用但尚未使用：**
- `entry.created_parsed` — 创建日期
- HTTP ETag/Last-Modified 用于条件 GET

### ezgmail（Gmail API）

在 `sources/gmail.py` 中使用。

**我们使用的功能：**
- `ezgmail.init(tokenFile, credentialsFile)` — OAuth2 初始化
- `ezgmail.search(query, maxResults)` → `GmailThread` 列表
- `thread.messages` — 延迟加载的消息列表（触发 API 调用）
- `thread.markAsRead()` — 标记线程已读
- `message.id`, `message.subject`, `message.timestamp`, `message.body`
- `message.messageObj` — 原始 Gmail API 消息字典（用于 HTML 提取）
- `message.sender` — 发件人信息
- `message.attachments` / `message._attachmentsInfo` — 附件访问
- `message.markAsUnread()` — 失败时标记未读
- `message.addLabel()` — 标签管理

**可用但尚未使用：**
- `message.recipient` — 收件人信息
- `message.originalBody` — 不去除引用部分的完整正文
- `message.downloadAttachment()` — 下载附件
- `message.removeLabel()` — 标签管理
- `thread.snippet` — 快速预览文本
- `ezgmail.unread()`, `ezgmail.recent()` — 便捷包装器
- `ezgmail.EMAIL_ADDRESS` — 已登录账户信息

**关键**: ezgmail 不提取 HTML 正文 — 只有 `TEXT/PLAIN`。我们在 `gmail.py` 中的自定义函数 `_extract_html_body()` 和 `_find_html_in_payload()` 填补了这一空白，通过遍历 `message.messageObj` payload 查找并解码 `TEXT/HTML` 部分。**这些函数不可删除。**

### OpenAI（AI 模块）

在 `ai/keyword_generator.py` 和 `ai/ai_filter.py` 中使用。

**我们使用的功能：**
- `client.chat.completions.create()` — LLM 交互
- JSON 模式 / 结构化输出提示
- 批处理以提高效率
- 并行 API 调用用于关键词候选生成

### python-dotenv（配置）

在 `core/config.py` 中使用。

**我们使用的功能：**
- `load_dotenv(dotenv_path, override=True)` — 从 `.env` 文件加载环境变量（`.env` 优先于系统环境变量）
- 通过 `_ensure_dotenv()` 延迟加载，确保配置在需要时可用

### CrossRef API（元数据补充）

在 `sources/crossref.py` 中使用。

**我们使用的功能：**
- REST API 用于 DOI 查找和标题搜索
- 通过 `User-Agent` 和 `mailto` 头部使用 polite pool 访问
- 字段选择（`select` 参数）以减少响应负载
- Jaccard 相似度用于标题匹配

### OpenAlex API（元数据补充）

在 `sources/openalex.py` 中使用。

**我们使用的功能：**
- REST API 用于开放元数据补充
- 倒排索引摘要重建
- 按相关性得分过滤概念
- Polite pool 访问
