name: RSS+GMAIL

on:
  schedule:
    # Beijing 00:00 = UTC 16:00 (previous day)
    - cron: "0 16 * * *"
  workflow_dispatch: {}

jobs:
  fetch:
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      OPENAI_BASE_URL: ${{ secrets.OPENAI_BASE_URL }}
      OPENAI_MODEL: ${{ secrets.OPENAI_MODEL }}
      RESEARCH_PROMPT: ${{ secrets.RESEARCH_PROMPT }}
      POLITE_POOL_EMAIL: ${{ secrets.POLITE_POOL_EMAIL }}
      GMAIL_TOKEN_JSON: ${{ secrets.GMAIL_TOKEN_JSON }}
      GMAIL_CREDENTIALS_JSON: ${{ secrets.GMAIL_CREDENTIALS_JSON }}
      GMAIL_SENDER_FILTER: ${{ secrets.GMAIL_SENDER_FILTER }}
      GMAIL_SENDER_MAP_JSON: ${{ secrets.GMAIL_SENDER_MAP_JSON }}
      GMAIL_TRASH_AFTER_PROCESS: "true"
      GMAIL_VERIFY_TRASH_AFTER_PROCESS: "true"
      GMAIL_VERIFY_TRASH_LIMIT: "50"
      GMAIL_TOKEN_FILE: feeds/token.json
      GMAIL_CREDENTIALS_FILE: feeds/credentials.json

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      - name: Install dependencies
        run: uv sync

      - name: Compute dates
        shell: bash
        run: |
          echo "RUN_DATE=$(TZ=Asia/Shanghai date +%Y_%m_%d)" >> $GITHUB_ENV
          echo "SINCE_DATE=$(TZ=Asia/Shanghai date -d '15 days ago' +%Y-%m-%d)" >> $GITHUB_ENV

      - name: Generate keywords from RESEARCH_PROMPT
        shell: bash
        run: |
          KEYWORDS=$(uv run python - <<'PY'
          import asyncio
          from paper_feed.ai.keyword_generator import KeywordGenerator

          async def main():
              kg = KeywordGenerator()
              keywords = await kg.extract_keywords()
              print(" ".join(keywords))

          asyncio.run(main())
          PY
          )
          echo "KEYWORDS=$KEYWORDS" >> $GITHUB_ENV

      - name: Prepare output dir
        run: mkdir -p output

      - name: RSS pipeline (15 days)
        shell: bash
        run: |
          uv run paper-feed fetch --source rss --since "$SINCE_DATE" --output output/rss_raw.json
          uv run paper-feed filter --input output/rss_raw.json --output output/rss_filtered.json --keywords $KEYWORDS
          uv run paper-feed filter --input output/rss_filtered.json --output output/rss_ai_filtered.json --ai
          uv run paper-feed enrich --input output/rss_ai_filtered.json --output output/rss_enriched.json --source all --concurrency 5
          uv run paper-feed export --input output/rss_enriched.json --output "output/${RUN_DATE}_RSS.json" --format json --include-metadata

      - name: Gmail pipeline (15 days)
        shell: bash
        run: |
          uv run paper-feed fetch --source gmail --since "$SINCE_DATE" --output output/gmail_raw.json
          uv run paper-feed filter --input output/gmail_raw.json --output output/gmail_filtered.json --keywords $KEYWORDS
          uv run paper-feed filter --input output/gmail_filtered.json --output output/gmail_ai_filtered.json --ai
          uv run paper-feed enrich --input output/gmail_ai_filtered.json --output output/gmail_enriched.json --source all --concurrency 5
          uv run paper-feed export --input output/gmail_enriched.json --output "output/${RUN_DATE}_GMAIL.json" --format json --include-metadata

      - name: Upload outputs
        uses: actions/upload-artifact@v4
        with:
          name: paper-feed-${{ env.RUN_DATE }}
          path: output/*.json
